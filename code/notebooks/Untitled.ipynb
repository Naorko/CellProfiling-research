{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf853118",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336fd840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../learning'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2fc347d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import makedirs, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15cb4f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import *\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f4c22d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r'/storage/users/g-and-n/plates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f83901",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = ['24792.csv','25912.csv','24509.csv','24633.csv','25987.csv','25680.csv','25422.csv','24517.csv','25664.csv','25575.csv','26674.csv','25945.csv','24687.csv','24752.csv','24311.csv','26622.csv','26641.csv','24594.csv','25676.csv','24774.csv','26562.csv','25997.csv','26640.csv','24562.csv','25938.csv','25708.csv','24321.csv','24735.csv','26786.csv','25571.csv','26666.csv','24294.csv','24640.csv','25985.csv','24661.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af312add",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 'AGP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb1af0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_plate = '24509.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d6e535a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [18:23<00:00, 33.22s/it]\n"
     ]
    }
   ],
   "source": [
    "df_test_mock_x, df_test_mock_y, df_test_treated_x, df_test_treated_y, df_train_x, df_train_y = \\\n",
    "                split_train_test('csvs/', csvs, test_plate, channel, inter_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6643642",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_method = 'Std'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c027aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = fit_scaler(df_train_x, scale_method)\n",
    "y_scaler = fit_scaler(df_train_y, scale_method)\n",
    "\n",
    "df_train_x_scaled = scale_data(df_train_x, x_scaler)\n",
    "df_train_y_scaled = scale_data(df_train_y, y_scaler)\n",
    "\n",
    "df_test_treated_x_scaled = scale_data(df_test_treated_x, x_scaler)\n",
    "df_test_treated_y_scaled = scale_data(df_test_treated_y, y_scaler)\n",
    "df_test_mock_x_scaled = scale_data(df_test_mock_x, x_scaler)\n",
    "df_test_mock_y_scaled = scale_data(df_test_mock_y, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd104ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dnn(task_channel, df_train_X, df_train_Y, test_plate):\n",
    "    \"\"\"\n",
    "    In this cell we are creating and training a multi layer perceptron (we refer to it as deep neural network, DNN) model\n",
    "\n",
    "    task_channel: the current channel that we aim to predict\n",
    "    df_train_X: contains all available features excluding the features related to 'task_channel' we aim to predict (train)\n",
    "    df_train_Y: contains all available features related to 'task_channel' only for the train\n",
    "    test_plate: the ID of a given plate. This information assist us while printing the results.\n",
    "\n",
    "    return: trained dnn model\n",
    "    \"\"\"\n",
    "    folder = 'dnn_models'\n",
    "    makedirs(folder, exist_ok=True)\n",
    "\n",
    "    # Stracture of the network#\n",
    "    inputs = Input(shape=(df_train_X.shape[1],))\n",
    "    dense1 = Dense(512, activation='relu')(inputs)\n",
    "    dense2 = Dense(256, activation='relu')(dense1)\n",
    "    dense3 = Dense(128, activation='relu')(dense2)\n",
    "    dense4 = Dense(100, activation='relu')(dense3)\n",
    "    dense5 = Dense(50, activation='relu')(dense4)\n",
    "    dense6 = Dense(25, activation='relu')(dense5)\n",
    "    dense7 = Dense(10, activation='relu')(dense6)\n",
    "    predictions = Dense(df_train_Y.shape[1], activation='sigmoid')(dense7)\n",
    "\n",
    "    # model compilation\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # model training\n",
    "    test_plate_number = test_plate[:5]\n",
    "    filepath = path.join(folder, f'{test_plate_number}_{task_channel}.h5')\n",
    "    my_callbacks = [\n",
    "        ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False,\n",
    "                        mode='auto', period=1)]\n",
    "    model.fit(df_train_X, df_train_Y, epochs=5, batch_size=1024 * 8, verbose=1, shuffle=True, validation_split=0.2,\n",
    "              callbacks=my_callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "996ff7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_dnn(task_channel, df_train_X, df_train_Y, test_plate, inter_channel=True):\n",
    "    \"\"\"\n",
    "    In this cell we are creating and training a multi layer perceptron (we refer to it as deep neural network, DNN) model\n",
    "\n",
    "    task_channel: the current channel that we aim to predict\n",
    "    df_train_X: contains all available features excluding the features related to 'task_channel' we aim to predict (train)\n",
    "    df_train_Y: contains all available features related to 'task_channel' only for the train\n",
    "    test_plate: the ID of a given plate. This information assist us while printing the results.\n",
    "\n",
    "    return: trained dnn model\n",
    "    \"\"\"\n",
    "    folder = 'dnn_models'\n",
    "    makedirs(folder, exist_ok=True)\n",
    "\n",
    "    if inter_channel:\n",
    "        # Stracture of the network#\n",
    "        inputs = Input(shape=(df_train_X.shape[1],))\n",
    "        dense1 = Dense(512, activation='relu')(inputs)\n",
    "        dense2 = Dense(256, activation='relu')(dense1)\n",
    "        dense3 = Dense(128, activation='relu')(dense2)\n",
    "        dense4 = Dense(100, activation='relu')(dense3)\n",
    "        dense5 = Dense(50, activation='relu')(dense4)\n",
    "        dense6 = Dense(25, activation='relu')(dense5)\n",
    "        dense7 = Dense(10, activation='relu')(dense6)\n",
    "        predictions = Dense(df_train_Y.shape[1], activation='sigmoid')(dense7)\n",
    "        \n",
    "    else:\n",
    "        inputs = Input(shape=(df_train_X.shape[1],))\n",
    "        dense1 = Dense(64, activation='relu')(inputs)\n",
    "        dense2 = Dense(32, activation='relu')(dense1)\n",
    "        dense3 = Dense(16, activation='relu')(dense2)\n",
    "        dense4 = Dense(8, activation='relu')(dense3)\n",
    "        dense5 = Dense(16, activation='relu')(dense4)\n",
    "        dense6 = Dense(32, activation='relu')(dense5)\n",
    "        dense7 = Dense(64, activation='relu')(dense6)\n",
    "        predictions = Dense(df_train_Y.shape[1], activation='linear')(dense7)\n",
    "\n",
    "    # model compilation\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # model training\n",
    "    test_plate_number = test_plate[:5]\n",
    "    inter_str = '' if inter_channel else '1to1'\n",
    "    filepath = path.join(folder, f'{test_plate_number}_{task_channel}{inter_str}.h5')\n",
    "    my_callbacks = [\n",
    "        ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False,\n",
    "                        mode='auto', period=1)]\n",
    "    model.fit(df_train_X, df_train_Y, epochs=10, batch_size=1024 * 8, verbose=1, shuffle=True, validation_split=0.2,\n",
    "              callbacks=my_callbacks)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a0147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1308762, 86), (1308762, 86))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_y_scaled.shape, df_train_x_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c8d01ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 3s 18ms/step - loss: 0.8187 - val_loss: 0.4678\n",
      "\n",
      "Epoch 00001: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.4342 - val_loss: 0.3569\n",
      "\n",
      "Epoch 00002: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3409 - val_loss: 0.3183\n",
      "\n",
      "Epoch 00003: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.3154 - val_loss: 0.3092\n",
      "\n",
      "Epoch 00004: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3077 - val_loss: 0.3027\n",
      "\n",
      "Epoch 00005: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.3001 - val_loss: 0.2878\n",
      "\n",
      "Epoch 00006: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2850 - val_loss: 0.2784\n",
      "\n",
      "Epoch 00007: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2772 - val_loss: 0.2744\n",
      "\n",
      "Epoch 00008: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 1s 8ms/step - loss: 0.2739 - val_loss: 0.2716\n",
      "\n",
      "Epoch 00009: saving model to dnn_models/24509_AGP1to1.h5\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 1s 7ms/step - loss: 0.2713 - val_loss: 0.2697\n",
      "\n",
      "Epoch 00010: saving model to dnn_models/24509_AGP1to1.h5\n"
     ]
    }
   ],
   "source": [
    "model =create_model_dnn(channel, df_train_x_scaled, df_train_y_scaled, test_plate, inter_channel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f07a59fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 86)]              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 64)                5568      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 86)                5590      \n",
      "=================================================================\n",
      "Total params: 16,702\n",
      "Trainable params: 16,702\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
