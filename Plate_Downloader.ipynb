{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "from os import path, scandir, makedirs, remove\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Selector\n",
    "import re\n",
    "from random import sample\n",
    "\n",
    "# Downloader\n",
    "from ftplib import FTP\n",
    "from progressbar import Bar, ETA,  FileTransferSpeed, Percentage, ProgressBar\n",
    "\n",
    "# Extractor\n",
    "import tarfile\n",
    "\n",
    "# Merger\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTP Modifible constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ftp constants\n",
    "FTP_LINK = r\"parrot.genomics.cn/gigadb/pub/10.5524/100001_101000/100351\"\n",
    "TIMEOUT = 10  # In seconds\n",
    "MAX_ATTEMPTS = 6  # Number of Retries upon timeout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select plates to download from the FTP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_selector(plate_amount, plate_numbers):\n",
    "    if plate_numbers:\n",
    "        reg = r\"({})\".format(\"|\".join(plate_numbers))\n",
    "    else:\n",
    "        reg = r\"\\d{5}\"\n",
    "    fmt = r\"^Plate_{}.tar.gz$\".format(reg)\n",
    "    pattern = re.compile(fmt)\n",
    "    ftp = connect_ftp()\n",
    "    plate_list = [plate for plate in ftp.nlst() if pattern.fullmatch(plate)]\n",
    "    if plate_amount and plate_amount < len(plate_list):\n",
    "        plate_list = sample(plate_list, plate_amount)\n",
    "    return ftp, plate_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the FTP server and returns the connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_ftp():\n",
    "    ftp_split = FTP_LINK.split(r\"/\")\n",
    "    ftp_domain = ftp_split[0]\n",
    "    ftp = FTP(ftp_domain, timeout=TIMEOUT)\n",
    "    ftp.login()\n",
    "    if len(ftp_split) > 1:\n",
    "        ftp_cwd = \"/\".join(ftp_split[1:])\n",
    "        ftp.cwd(ftp_cwd)\n",
    "    return ftp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a single plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(ftp, plate, dest_file):\n",
    "    # https://stackoverflow.com/questions/51684008/show-ftp-download-progress-in-python-progressbar\n",
    "    widgets = ['Downloading: %s ' % plate, Percentage(), ' ',\n",
    "               Bar(marker='â–ˆ', left='[', right=']'),\n",
    "               ' ', ETA(), ' ', FileTransferSpeed()]\n",
    "    size = ftp.size(plate)\n",
    "    prog_bar = ProgressBar(widgets=widgets, maxval=size)\n",
    "    prog_bar.start()\n",
    "    cur_file = open(dest_file, 'wb')\n",
    "\n",
    "    def file_write(data):\n",
    "        cur_file.write(data)\n",
    "        prog_bar.update(prog_bar.value + len(data))\n",
    "\n",
    "    # https://stackoverflow.com/questions/8323607/download-big-files-via-ftp-with-python\n",
    "    attempts_left = MAX_ATTEMPTS\n",
    "    while size != cur_file.tell():\n",
    "        try:\n",
    "            if cur_file.tell():\n",
    "                ftp.retrbinary(\"RETR \" + plate, file_write, rest=cur_file.tell())\n",
    "            else:\n",
    "                ftp.retrbinary(\"RETR \" + plate, file_write)\n",
    "\n",
    "            cur_file.close()\n",
    "            prog_bar.finish()\n",
    "            break\n",
    "        except Exception as timeout_ex:\n",
    "            if attempts_left:\n",
    "                attempts_left -= 1\n",
    "                print(\" Got {} Retry #{}\".format(timeout_ex, MAX_ATTEMPTS - attempts_left))\n",
    "                ftp = connect_ftp()\n",
    "            else:\n",
    "                print(\" Failed to download {}\".format(plate))\n",
    "                cur_file.close()\n",
    "                del cur_file\n",
    "                remove(dest_file)\n",
    "                prog_bar.finish(dirty=True)\n",
    "                break\n",
    "    return ftp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iteravte over the plate plist and download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_plates(ftp, destination, plate_list):\n",
    "    makedirs(destination, exist_ok=True)\n",
    "\n",
    "    for plate in plate_list:\n",
    "        dest = path.join(destination, plate)\n",
    "        if path.lexists(dest):\n",
    "            print(\"Warning: {} already exist, skipping..\".format(plate))\n",
    "            continue\n",
    "\n",
    "        ftp = download_file(ftp, plate, dest)\n",
    "\n",
    "    ftp.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor_file(plate_file, destination):\n",
    "    plate_basename = path.basename(plate_file)\n",
    "    plate_name = plate_basename.split(\".\")[0]\n",
    "    plate_number = plate_name.split(\"_\")[1]\n",
    "\n",
    "    sql_file = r\"gigascience_upload/{}/extracted_features/{}.sqlite\".format(plate_name, plate_number)\n",
    "    profile_file = r\"gigascience_upload/{}/profiles/mean_well_profiles.csv\".format(plate_name)\n",
    "\n",
    "    tar = tarfile.open(plate_file, \"r:gz\")\n",
    "\n",
    "    for infile in [sql_file, profile_file]:\n",
    "        tar_member = tar.getmember(infile)\n",
    "        tar_member.name = path.basename(infile)\n",
    "        curr_dest = path.join(destination, plate_name)\n",
    "        extracted_file = path.join(curr_dest, tar_member.name)\n",
    "        if path.lexists(extracted_file):\n",
    "            print(\"Warning: {}/{} already extracted, skipping...\".format(plate_name, tar_member.name))\n",
    "            continue\n",
    "        tar.extract(tar_member, curr_dest)\n",
    "\n",
    "    tar.close()\n",
    "    del tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterate over the gz files and extract them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(tars_dir, plate_list, destination):\n",
    "    makedirs(destination, exist_ok=True)\n",
    "    tars = [f.name for f in scandir(tars_dir) if f.is_file()]\n",
    "    tars = [tar for tar in tars if tar in plate_list]\n",
    "    p_bar = tqdm(tars)\n",
    "    for tar in p_bar:\n",
    "        p_bar.set_description(\"Extracting {}\".format(tar))\n",
    "        extractor_file(path.join(tars_dir, tar), destination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merger(directory, plate_folders, destination):\n",
    "    makedirs(destination, exist_ok=True)\n",
    "    dir_list = [f.name for f in scandir(directory) if f.is_dir()]\n",
    "    dir_list = [fld for fld in dir_list if fld in plate_folders]\n",
    "\n",
    "    p_bar = tqdm(dir_list)\n",
    "    for plate_folder in p_bar:\n",
    "        p_bar.set_description(\"Merging {}\".format(plate_folder))\n",
    "        folder_path = path.join(directory, plate_folder)\n",
    "        plate_number = plate_folder.split('_')[1]\n",
    "        output = path.join(destination, plate_number+\".csv\")\n",
    "        if path.lexists(output):\n",
    "            print(\"Warning: {} already merged, skipping...\".format(plate_folder))\n",
    "            continue\n",
    "\n",
    "        sql_file = path.join(folder_path, plate_number+\".sqlite\")\n",
    "        well_file = path.join(folder_path, \"mean_well_profiles.csv\")\n",
    "\n",
    "        df_well = pd.read_csv(well_file,\n",
    "                              index_col=\"Metadata_Well\",\n",
    "                              usecols=[\"Metadata_Well\", \"Metadata_ASSAY_WELL_ROLE\", \"Metadata_broad_sample\"])\n",
    "\n",
    "        con = sqlite3.connect(sql_file)\n",
    "        query = \"SELECT Cells.*, Image.Image_Metadata_Well FROM Cells \" \\\n",
    "                \"INNER JOIN Image ON Cells.ImageNumber = Image.ImageNumber\"\n",
    "        df_cells = pd.read_sql_query(query, con)\n",
    "        con.close()\n",
    "\n",
    "        df_join = df_cells.join(df_well, \"Image_Metadata_Well\", \"inner\")\n",
    "        df_join.to_csv(output, index=False)\n",
    "        del df_well, df_cells, df_join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(working_path, plate_amount, plate_numbers):\n",
    "    ftp, plate_list = plate_selector(plate_amount, plate_numbers)\n",
    "    \n",
    "    download_path = path.join(working_path, \"tars\")\n",
    "    download_plates(ftp, download_path, plate_list)\n",
    "    \n",
    "    extract_path = path.join(working_path, \"extracted\")\n",
    "    extractor(download_path, plate_list, extract_path)\n",
    "    \n",
    "    merge_path = path.join(working_path, \"csvs\")\n",
    "    plate_folders = [plate.split('.')[0] for plate in plate_list]\n",
    "    merger(extract_path, plate_folders, merge_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Input Parameters and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: Plate_26521.tar.gz 100% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] Time:  0:09:15   4.2 MiB/s\n",
      "Downloading: Plate_24773.tar.gz 100% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] Time:  0:07:52   3.3 MiB/s\n",
      "Downloading: Plate_25690.tar.gz 100% [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] Time:  0:09:13   2.8 MiB/s\n",
      "Extracting Plate_26521.tar.gz: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [01:55<00:00, 38.37s/it]\n",
      "Merging Plate_26521: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [09:57<00:00, 199.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done\n"
     ]
    }
   ],
   "source": [
    "def valid_numbers(str_list):\n",
    "    for st in str_list:\n",
    "        if not st.isnumeric():\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "working_path = input(\"Enter your working path: \")\n",
    "argv = input(\"Enter your arguments: \").split(' ')\n",
    "\n",
    "\n",
    "if len(argv) < 2:\n",
    "    print(\"Please follow the following usages:\")\n",
    "    print(\"Usage: -n [plate_amount]\")\n",
    "    print(\"Usage: -l [plate_number1] [plate_number2] ...\")\n",
    "    print(\"Usage: -n [plate_amount] -l [plate_number1] [plate_number2] ...\")\n",
    "else:\n",
    "    makedirs(working_path, exist_ok=True)\n",
    "\n",
    "    plate_amount = None\n",
    "    plate_numbers = None\n",
    "\n",
    "    i = 0\n",
    "    is_ok = True\n",
    "    if argv[i] == \"-n\":\n",
    "        if not argv[i+1].isnumeric():\n",
    "            print(\"plate_amount has to be a valid number\")\n",
    "            is_ok = False\n",
    "        else:\n",
    "            plate_amount = int(argv[i+1])\n",
    "            i += 2\n",
    "\n",
    "    if i < len(argv)-1 and argv[i] == \"-l\":\n",
    "        if not valid_numbers(argv[i+1:]):\n",
    "            print(\"plate numbers have to be valid numbers\")\n",
    "            is_ok = False\n",
    "        else:\n",
    "            plate_numbers = argv[i+1:]\n",
    "\n",
    "    if is_ok:\n",
    "        main(working_path, plate_amount, plate_numbers)\n",
    "        print(\"All done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}